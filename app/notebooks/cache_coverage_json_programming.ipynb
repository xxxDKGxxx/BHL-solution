{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Pobieramy ścieżkę do katalogu głównego projektu (dwa poziomy wyżej: ../..)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "\n",
    "# Dodajemy ją do ścieżek Pythona, jeśli jej tam nie ma\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ],
   "id": "e12af50ad35dd465",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "from app.database.database import Database\n",
    "from app.database.sentence_transformer_embedder import SentenceTransformerEmbedder\n",
    "from app.handler.defaulthandler import PromptHandler\n",
    "from app.interface.abstractmodel import AbstractModel\n",
    "from app.prompts_classification.fact_or_generative_classifier import FactOrGenerativeClassifier\n",
    "\n",
    "with open('programming_questions.json', 'r') as f:\n",
    "\tdata = json.load(f)\n",
    "\n",
    "data"
   ],
   "id": "e20fe6e210c2d65f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class MockLLM(AbstractModel):\n",
    "\n",
    "\tdef generate_answer(self, prompt: str) -> str:\n",
    "\t\treturn \"Answer\"\n",
    "\n",
    "\n",
    "db = Database(SentenceTransformerEmbedder())\n",
    "\n",
    "handler = PromptHandler(db, MockLLM(), FactOrGenerativeClassifier())\n",
    "\n",
    "for question in data:\n",
    "\tprint(f\"Question: {question['original_question']}\")\n",
    "\tdb.insert(question[\"original_question\"], question[\"cached_answer\"])"
   ],
   "id": "8929faeeac619e5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "expected_hits = 0\n",
    "got_hits = 0\n",
    "expected_misses = 0\n",
    "got_misses = 0\n",
    "\n",
    "for question in data:\n",
    "    for positive_similar in question[\"paraphrases\"]:\n",
    "        print(f\"Checking paraphrase: {positive_similar}\")\n",
    "\n",
    "        _, is_cached, _ = handler.generate_answer(positive_similar, False)\n",
    "\n",
    "        if is_cached:\n",
    "            got_hits += 1\n",
    "        expected_hits += 1\n",
    "\n",
    "    for negative in question[\"hard_negatives\"]:\n",
    "        print(f\"Checking negative: {negative}\")\n",
    "\n",
    "        _, is_cached, _ = handler.generate_answer(negative, False)\n",
    "\n",
    "        if not is_cached:\n",
    "            got_misses += 1\n",
    "        expected_misses += 1\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Processed question group: {question['original_question']}\")\n",
    "    print(f\"  > Hits (Cache Hits):   {got_hits}/{expected_hits}\")\n",
    "    print(f\"  > Misses (Cache Miss): {got_misses}/{expected_misses}\")\n",
    "    print(\"-\" * 40 + \"\\n\")\n",
    "\n",
    "print(\"=== FINAL SUMMARY ===\")\n",
    "print(f\"Total Accuracy (Hits):   {got_hits}/{expected_hits} ({(got_hits/expected_hits)*100:.1f}%)\")\n",
    "print(f\"Total Accuracy (Misses): {got_misses}/{expected_misses} ({(got_misses/expected_misses)*100:.1f}%)\")"
   ],
   "id": "27b179a5097bdd58",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
