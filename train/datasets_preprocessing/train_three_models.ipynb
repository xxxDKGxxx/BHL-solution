{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../../train', '..'))\n",
    "app_root = os.path.abspath(os.path.join(project_root, '../../app', '..'))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    sys.path.append(app_root)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datasets_preprocessing import load_json_data, make_pipeline\n",
    "import pandas as pd\n",
    "\n",
    "math_pipeline = make_pipeline('math')\n",
    "\n",
    "X_json_raw = load_json_data('datasets/math')\n",
    "math_pipeline.fit_transform(X_json_raw)\n",
    "\n",
    "math_df = pd.read_csv(os.path.join('csv_question_files', 'math.csv'))\n",
    "math_df.head(10)"
   ],
   "id": "991c077de874cc2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bio_pipeline = make_pipeline('bio')\n",
    "\n",
    "X_json_raw = load_json_data('datasets/bio')\n",
    "bio_pipeline.fit_transform(X_json_raw)\n",
    "\n",
    "bio_df = pd.read_csv(os.path.join('csv_question_files', 'bio.csv'))\n",
    "bio_df.head(10)"
   ],
   "id": "614cc2b85e2e413",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "code_pipeline = make_pipeline('code')\n",
    "\n",
    "X_json_raw = load_json_data('datasets/code')\n",
    "code_pipeline.fit_transform(X_json_raw)\n",
    "\n",
    "code_df = pd.read_csv(os.path.join('csv_question_files', 'code.csv'))\n",
    "code_df.head(10)"
   ],
   "id": "9b858933af03faee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_samples = 6000\n",
    "half_samples = n_samples // 2\n",
    "\n",
    "full_df = pd.concat(\n",
    "\t[\n",
    "\t\tmath_df.sample(n=n_samples, random_state=42),\n",
    "\t\tbio_df.sample(n=half_samples , random_state=42),\n",
    "\t\tcode_df.sample(n=half_samples, random_state=42)\n",
    "\t],\n",
    "    ignore_index=True,\n",
    "\taxis=0\n",
    ")\n",
    "\n",
    "full_df"
   ],
   "id": "334959be2c25435d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Math Model",
   "id": "bb0e9b9f9dadebae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## SVM + TF-IDF",
   "id": "80a886a6af1409de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from train.reporting.sentence_transformer_sklearn_adapter import SentenceTransformerSklearnAdapter\n",
    "from sklearn.pipeline import Pipeline\n",
    "from train.reporting.model_interface import ModelInterface\n",
    "from sklearn.svm import SVC"
   ],
   "id": "da35d619398c9508",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class TextSVMWrapper(ModelInterface):\n",
    "    def get_params(self) -> Dict[str, Any]:\n",
    "\t    return self.model.get_params()\n",
    "\n",
    "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
    "\t    return self.model.predict_proba(X)\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "\t    return self.model.steps[0][1]\n",
    "\n",
    "    def __init__(self, C=1.0):\n",
    "        # Pipeline: Najpierw zamiana tekstu na liczby (TF-IDF), potem klasyfikator SVM\n",
    "        self.model = Pipeline([\n",
    "            ('tfidf', SentenceTransformerSklearnAdapter()),\n",
    "            ('svm', SVC(C=C, random_state=42, probability=True, kernel='linear'))\n",
    "        ])\n",
    "        self.C = C\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        # SVM w sklearn nie wspiera śledzenia historii loss per epoka w prosty sposób,\n",
    "        # więc po prostu trenujemy model.\n",
    "        self.model.fit(X, y)\n",
    "        self.is_fitted = True\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def get_loss_history(self):\n",
    "        # SVM ze sklearn nie udostępnia historii funkcji straty w czasie treningu.\n",
    "        # Zwracamy pusty słownik, aby Reporter wiedział, że ma pominąć wykres.\n",
    "        return {}\n",
    "\n",
    "    def get_new_instance(self):\n",
    "        # Zwraca nową, czystą instancję (potrzebne do Cross Validation w Reporterze)\n",
    "        return TextSVMWrapper(C=self.C)\n",
    "\n",
    "    def get_feature_importance(self):\n",
    "        \"\"\"\n",
    "        Dla tekstu 'ważność cech' to słowa, które najsilniej wskazują na daną kategorię.\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            return {}\n",
    "\n",
    "        try:\n",
    "            # Pobieramy słowa z wektoryzatora\n",
    "            feature_names = self.model.named_steps['tfidf'].get_feature_names_out()\n",
    "            # Pobieramy wagi z SVM\n",
    "            coefs = self.model.named_steps['svm'].coef_.copy()\n",
    "\n",
    "            # Uwaga: SVM binarny ma 1 wymiar wag, wieloklasowy ma (n_klas, n_cech).\n",
    "            # Dla uproszczenia bierzemy średnią siłę wpływu słowa (wartość bezwzględna) dla wszystkich klas.\n",
    "            # To pokaże słowa, które są ogólnie najbardziej \"decydujące\".\n",
    "            avg_coefs = np.mean(np.abs(coefs), axis=0)\n",
    "            avg_coefs = np.ravel(avg_coefs)\n",
    "\n",
    "            # Tworzymy słownik {słowo: waga}\n",
    "            importance_dict = dict(zip(feature_names, avg_coefs))\n",
    "            return importance_dict\n",
    "        except Exception as e:\n",
    "            print(f\"Nie udało się pobrać ważności cech: {e}\")\n",
    "            return {}"
   ],
   "id": "d6bdbd5600cbf52c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from train.reporting.model_reporter import ModelReporter\n",
    "\n",
    "report_df = full_df\n",
    "\n",
    "reporter = ModelReporter(TextSVMWrapper(C=1.0), report_df['question'],\n",
    "                         report_df['math'])\n"
   ],
   "id": "a4ad4da013408947",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "reporter.generate_report()",
   "id": "fbb66915d317e71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "reporter.plot_tsne()",
   "id": "cea09c7f7835386d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "reporter.plot_wordclouds()",
   "id": "1bffa79be8cc703b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "reporter.plot_confidence_distribution()",
   "id": "c0c1b59aa2d7ff09",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
