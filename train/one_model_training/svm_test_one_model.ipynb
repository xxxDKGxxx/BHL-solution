{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Testowanie działania zapisanego modelu",
   "id": "cb96c9a257158890"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ],
   "id": "7b60174b7c0488bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Funkcja do załadowania wybranego zbioru testowego",
   "id": "19db02eb95cb3b7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from train.reporting.model_interface import ModelInterface\n",
    "from train.reporting.svm_model_wrapper import SVMModelWrapper\n",
    "from typing import Tuple\n",
    "import pickle\n",
    "\n",
    "def import_model_and_test_set(path: str) -> Tuple[ModelInterface, pd.DataFrame]:\n",
    "    with open (path + \"/model.pkl\", 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    test_set = pd.read_csv(path + \"/test_set.csv\", index_col=0)\n",
    "\n",
    "    return model, test_set\n",
    "\n",
    "model, _ = import_model_and_test_set(\"../saved_models/1 model\")"
   ],
   "id": "bb6d5fb4d2fca542"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "test_set_number = 2 # 1 lub 2",
   "id": "59f9807bcac3bcd7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_df = pd.read_csv(f\"../datasets_preprocessing/test_all_models/test_{test_set_number}.csv\", index_col=0)\n",
    "\n",
    "test_df.drop_duplicates(subset=[\"question\"], keep=\"first\")\n",
    "test_df"
   ],
   "id": "2aeabd29dcf66cfa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dodanie kolumny określającej kategorię pytania",
   "id": "ef0c61d70862c944"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "test_df['real_class'] = (test_df['math'] * 0 + test_df['bio'] * 1 + test_df['code'] * 2)",
   "id": "50ab8acbfb82d8b4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Badanie predykcji modelu dla każdej kategorii i zapisanie ich w ramce danych",
   "id": "b855ec94119289a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "proba_arr = model.predict_proba(test_df[\"question\"])\n",
    "\n",
    "test_df[\"math_preds\"] = proba_arr[:, 0]\n",
    "test_df[\"bio_preds\"] = proba_arr[:, 1]\n",
    "test_df[\"code_preds\"] = proba_arr[:, 2]"
   ],
   "id": "accfac32e513c07"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "test_df",
   "id": "3881390798a75894"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Zapisanie przewidzianych klas w ramce danych (-1, gdy maksymalne prawdopodobieństwo nie przekracza 0.5)",
   "id": "44ff35a4da461a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "cols = ['math_preds', 'bio_preds', 'code_preds']\n",
    "\n",
    "max_vals = test_df[cols].max(axis=1)\n",
    "max_names = test_df[cols].idxmax(axis=1)\n",
    "\n",
    "class_mapping = {'math_preds': 0, 'bio_preds': 1, 'code_preds': 2}\n",
    "predicted_classes = max_names.map(class_mapping)\n",
    "\n",
    "test_df['predicted_class'] = np.where(max_vals > 0.5, predicted_classes, -1)\n",
    "test_df"
   ],
   "id": "292eb8842baf7a6f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Efektywność modelu",
   "id": "915502e68fe8b5e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(test_df['real_class'], test_df['predicted_class'])"
   ],
   "id": "b084e380038a5d20"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Przykładowe pytania, dla których model niepoprawnie przewidział kategorię",
   "id": "189ec3882edb6fc5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "wrong_questions_sample = test_df[test_df['real_class'] != test_df['predicted_class']].sample(n=10)\n",
    "\n",
    "wrong_questions_sample"
   ],
   "id": "509734dc4d27883a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for question in wrong_questions_sample['question']:\n",
    "    print(question)"
   ],
   "id": "a6adb7bcb1320000"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
