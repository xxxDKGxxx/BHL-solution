{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-19T19:45:19.022711379Z",
     "start_time": "2026-01-19T19:45:18.956845257Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../../train', '..'))\n",
    "app_root = os.path.abspath(os.path.join(project_root, '../../app', '..'))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    sys.path.append(app_root)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T19:45:25.475404254Z",
     "start_time": "2026-01-19T19:45:19.024565747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets_preprocessing import load_json_data, make_pipeline\n",
    "import pandas as pd\n",
    "\n",
    "math_pipeline = make_pipeline('math')\n",
    "\n",
    "X_json_raw = load_json_data('datasets/math')\n",
    "math_pipeline.fit_transform(X_json_raw)\n",
    "\n",
    "math_df = pd.read_csv(os.path.join('csv_question_files', 'math.csv'))\n",
    "math_df.head(10)"
   ],
   "id": "991c077de874cc2d",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpd\u001B[39;00m\n\u001B[32m      4\u001B[39m math_pipeline = make_pipeline(\u001B[33m'\u001B[39m\u001B[33mmath\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m X_json_raw = \u001B[43mload_json_data\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mdatasets/math\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      7\u001B[39m math_pipeline.fit_transform(X_json_raw)\n\u001B[32m      9\u001B[39m math_df = pd.read_csv(os.path.join(\u001B[33m'\u001B[39m\u001B[33mcsv_question_files\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mmath.csv\u001B[39m\u001B[33m'\u001B[39m))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/BHL-solution/train/datasets_preprocessing/datasets_preprocessing.py:16\u001B[39m, in \u001B[36mload_json_data\u001B[39m\u001B[34m(dir_path)\u001B[39m\n\u001B[32m     14\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(in_filename, \u001B[33m'\u001B[39m\u001B[33mr\u001B[39m\u001B[33m'\u001B[39m, encoding=\u001B[33m'\u001B[39m\u001B[33mutf-8\u001B[39m\u001B[33m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m infile:\n\u001B[32m     15\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m infile:\n\u001B[32m---> \u001B[39m\u001B[32m16\u001B[39m             data.append(\u001B[43mjson\u001B[49m\u001B[43m.\u001B[49m\u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mline\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/lib/python3.13/json/__init__.py:352\u001B[39m, in \u001B[36mloads\u001B[39m\u001B[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[39m\n\u001B[32m    347\u001B[39m     s = s.decode(detect_encoding(s), \u001B[33m'\u001B[39m\u001B[33msurrogatepass\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m    349\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[32m    350\u001B[39m         parse_int \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m parse_float \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[32m    351\u001B[39m         parse_constant \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_pairs_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kw):\n\u001B[32m--> \u001B[39m\u001B[32m352\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_decoder\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    353\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    354\u001B[39m     \u001B[38;5;28mcls\u001B[39m = JSONDecoder\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/lib/python3.13/json/decoder.py:346\u001B[39m, in \u001B[36mJSONDecoder.decode\u001B[39m\u001B[34m(self, s, _w)\u001B[39m\n\u001B[32m    341\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001B[39;00m\n\u001B[32m    342\u001B[39m \u001B[33;03mcontaining a JSON document).\u001B[39;00m\n\u001B[32m    343\u001B[39m \n\u001B[32m    344\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    345\u001B[39m obj, end = \u001B[38;5;28mself\u001B[39m.raw_decode(s, idx=_w(s, \u001B[32m0\u001B[39m).end())\n\u001B[32m--> \u001B[39m\u001B[32m346\u001B[39m end = \u001B[43m_w\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mend\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    347\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m end != \u001B[38;5;28mlen\u001B[39m(s):\n\u001B[32m    348\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m JSONDecodeError(\u001B[33m\"\u001B[39m\u001B[33mExtra data\u001B[39m\u001B[33m\"\u001B[39m, s, end)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bio_pipeline = make_pipeline('bio')\n",
    "\n",
    "X_json_raw = load_json_data('datasets/bio')\n",
    "bio_pipeline.fit_transform(X_json_raw)\n",
    "\n",
    "bio_df = pd.read_csv(os.path.join('csv_question_files', 'bio.csv'))\n",
    "bio_df.head(10)"
   ],
   "id": "614cc2b85e2e413",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "code_pipeline = make_pipeline('code')\n",
    "\n",
    "X_json_raw = load_json_data('datasets/code')\n",
    "code_pipeline.fit_transform(X_json_raw)\n",
    "\n",
    "code_df = pd.read_csv(os.path.join('csv_question_files', 'code.csv'))\n",
    "code_df.head(10)"
   ],
   "id": "9b858933af03faee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "full_df = pd.concat(\n",
    "\t[\n",
    "\t\tmath_df,\n",
    "\t\tbio_df,\n",
    "\t\tcode_df\n",
    "\t],\n",
    "    ignore_index=True,\n",
    "\taxis=0\n",
    ")\n",
    "\n",
    "full_df = full_df.drop_duplicates(subset=[\"question\"], keep=\"first\")\n",
    "full_df"
   ],
   "id": "334959be2c25435d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from typing import Dict, Any\n",
    "from train.reporting.model_interface import ModelInterface\n",
    "\n",
    "\n",
    "class TextSVMWrapper(ModelInterface):\n",
    "\tdef get_params(self) -> Dict[str, Any]:\n",
    "\t\treturn self.model.get_params()\n",
    "\n",
    "\tdef predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
    "\t\treturn self.model.predict_proba(X)\n",
    "\n",
    "\tdef get_vectorizer(self):\n",
    "\t\treturn self.model.steps[0][1]\n",
    "\n",
    "\tdef __init__(self, C=1.0):\n",
    "\t\t# Pipeline: Najpierw zamiana tekstu na liczby (TF-IDF), potem klasyfikator SVM\n",
    "\t\tself.model = Pipeline([\n",
    "\t\t\t('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "\t\t\t('svm', SVC(C=C, random_state=42, probability=True, kernel='linear'))\n",
    "\t\t])\n",
    "\t\tself.C = C\n",
    "\t\tself.is_fitted = False\n",
    "\n",
    "\tdef fit(self, X, y, X_val=None, y_val=None):\n",
    "\t\t# SVM w sklearn nie wspiera śledzenia historii loss per epoka w prosty sposób,\n",
    "\t\t# więc po prostu trenujemy model.\n",
    "\t\tself.model.fit(X, y)\n",
    "\t\tself.is_fitted = True\n",
    "\n",
    "\tdef predict(self, X):\n",
    "\t\treturn self.model.predict(X)\n",
    "\n",
    "\tdef get_loss_history(self):\n",
    "\t\t# SVM ze sklearn nie udostępnia historii funkcji straty w czasie treningu.\n",
    "\t\t# Zwracamy pusty słownik, aby Reporter wiedział, że ma pominąć wykres.\n",
    "\t\treturn {}\n",
    "\n",
    "\tdef get_new_instance(self):\n",
    "\t\t# Zwraca nową, czystą instancję (potrzebne do Cross Validation w Reporterze)\n",
    "\t\treturn TextSVMWrapper(C=self.C)\n",
    "\n",
    "\tdef get_feature_importance(self):\n",
    "\t\t\"\"\"\n",
    "        Dla tekstu 'ważność cech' to słowa, które najsilniej wskazują na daną kategorię.\n",
    "        \"\"\"\n",
    "\t\tif not self.is_fitted:\n",
    "\t\t\treturn {}\n",
    "\n",
    "\t\ttry:\n",
    "\t\t\tfeature_names = self.model.named_steps['tfidf'].get_feature_names_out()\n",
    "\t\t\tcoefs = self.model.named_steps['svm'].coef_.copy()\n",
    "\n",
    "\t\t\tavg_coefs = np.mean(np.abs(coefs), axis=0)\n",
    "\t\t\tavg_coefs = np.ravel(avg_coefs)\n",
    "\n",
    "\t\t\t# Tworzymy słownik {słowo: waga}\n",
    "\t\t\timportance_dict = dict(zip(feature_names, avg_coefs))\n",
    "\t\t\treturn importance_dict\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"Nie udało się pobrać ważności cech: {e}\")\n",
    "\t\t\treturn {}"
   ],
   "id": "c5941562098f9e4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from train.reporting.model_interface import ModelInterface\n",
    "from typing import Tuple\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def import_model_and_its_test_set(path: str) -> Tuple[ModelInterface, pd.DataFrame]:\n",
    "        with open(path + \"/model.pkl\", \"rb\") as f:\n",
    "            model = pickle.load(f)\n",
    "\n",
    "\n",
    "        test_set = pd.read_csv(\n",
    "            path + \"/test_set.csv\", index_col=0)\n",
    "        return model, test_set\n",
    "\n",
    "\n",
    "\n",
    "math_model, math_test_set = import_model_and_its_test_set(\"reports/runs_with_model_saved/math\")\n",
    "bio_model, bio_test_set = import_model_and_its_test_set(\"reports/runs_with_model_saved/bio\")\n",
    "code_model, code_test_set = import_model_and_its_test_set(\"reports/runs_with_model_saved/code\")\n",
    "\n",
    "math_test_set = math_test_set.rename(columns={\"target\": \"math_target\"})\n",
    "bio_test_set = bio_test_set.rename(columns={\"target\": \"bio_target\"})\n",
    "code_test_set = code_test_set.rename(columns={\"target\": \"code_target\"})"
   ],
   "id": "1ac1a23b148e36d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "math_test_set",
   "id": "aed8e251fbb0935d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "bio_test_set",
   "id": "f278c7c489802c66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "code_test_set",
   "id": "3a88b21e87381495",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_df = pd.DataFrame(pd.concat([math_test_set[\"question\"], bio_test_set[\"question\"], code_test_set[\"question\"]],\n",
    "                    names=[\"question\"], ignore_index=True))\n",
    "\n",
    "test_df.drop_duplicates(subset=[\"question\"], keep=\"first\")\n",
    "test_df"
   ],
   "id": "ffdff227b18cc5a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_df_with_labels = test_df.merge(full_df.drop(columns=\"tags_str\"), on=\"question\", how=\"left\")\n",
    "\n",
    "test_df_with_labels"
   ],
   "id": "d049c520260b1882",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_df_with_labels[\"real_class\"] = (test_df_with_labels[\"math\"] * 0 +  test_df_with_labels[\"bio\"] * 1 +\n",
    "                                 test_df_with_labels[\"code\"]\n",
    "                                * 2)\n",
    "test_df_with_labels"
   ],
   "id": "5313a22db126835",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_df_with_labels[\"math_preds\"] = math_model.predict_proba(test_df_with_labels[\"question\"])[:, 1]\n",
    "test_df_with_labels[\"bio_preds\"] = bio_model.predict_proba(test_df_with_labels[\"question\"])[:, 1]\n",
    "test_df_with_labels[\"code_preds\"] = code_model.predict_proba(test_df_with_labels[\"question\"])[:, 1]"
   ],
   "id": "960646fe54c71a81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_df_with_labels",
   "id": "40aef67f54c2ba40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cols = ['math_preds', 'bio_preds', 'code_preds']\n",
    "\n",
    "max_values = test_df_with_labels[cols].max(axis=1)\n",
    "max_names = test_df_with_labels[cols].idxmax(axis=1)\n",
    "\n",
    "class_mapping = {'math_preds': 0, 'bio_preds': 1, 'code_preds': 2}\n",
    "\n",
    "predicted_class = max_names.map(class_mapping)\n",
    "\n",
    "test_df_with_labels['predicted_class'] = np.where(max_values > 0.5, predicted_class, -1)\n",
    "test_df_with_labels\n"
   ],
   "id": "e81c1cfef9886e94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "accuracy_score(test_df_with_labels[\"real_class\"], test_df_with_labels[\"predicted_class\"])"
   ],
   "id": "d9d1863f06fc03b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_df_with_labels.sample(n=10)",
   "id": "df86f41c84831cba",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
