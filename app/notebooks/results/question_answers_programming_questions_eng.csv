question,answer
What is a Hash Map?,"('A **Hash Map** (also known as a Hash Table, Dictionary, or Associative Array) is a data structure that stores collections of elements as unique (key, value) pairs. Its primary advantage is providing extremely fast access to data.\n\n### Underlying Data Structure (How it Works)\n\nA Hash Map uses two core components: an internal array (the bucket array) and a **hash function**.\n\n1.  **Hashing:** When a key is inserted, the hash function converts the key into a numerical hash code.\n2.  **Indexing:** This hash code is then mathematically constrained (often via the modulo operator) to fit within the bounds of the bucket array, determining the exact index where the value is stored.\n\nThis structure allows average-case lookup, insertion, and deletion operations to approach $O(1)$ (constant time complexity). If two distinct keys map to the same index (a **collision**), the Hash Map must employ collision resolution strategies, commonly through **separate chaining** (using linked lists within the bucket) or **open addressing**.\n\n### Common Use Cases in Software Development\n\n*   **Caches and Memoization:** Hash Maps are used extensively to store the results of expensive computations, ensuring the application can retrieve the value instantly the next time that input key is requested.\n*   **Database Indexing:** Mapping primary keys to the physical memory location of a record for rapid data retrieval.\n*   **Configuration Storage:** Storing user settings, environment variables, or program flags (e.g., mapping a setting name to its Boolean or string value).\n*   **Symbol Tables:** Used within compilers to map identifiers (like variable names) to their associated attributes and memory locations.', False, 'None')"
What is the MVC design pattern?,"('The **Model-View-Controller (MVC) design pattern** is an architectural pattern that separates an application into three interconnected parts. Its main purpose in software architecture is to decouple the internal representation of information (data and business logic) from the way that data is presented to and accepted from the user, thereby promoting **modularity**, **reusability**, and **maintainability**.\n\n### Distinct Roles of the Components\n\n1.  **Model:**\n    *   **Role:** Manages the application\'s data, business logic, and rules. The Model is responsible for retrieving information from the database, performing computations, and ensuring data integrity.\n    *   **Clarification:** It has no direct knowledge of the User Interface (UI) and should be designed to be independent of the View.\n\n2.  **View:**\n    *   **Role:** Handles the presentation of data to the user and manages user input mechanisms (the UI). It visualizes the data provided by the Model.\n    *   **Clarification:** The View requests data from the Model but should not contain business logic or data manipulation code.\n\n3.  **Controller:**\n    *   **Role:** Acts as the intermediary, receiving input from the View (user actions), translating that input into commands for the Model, and selecting the appropriate View for display.\n    *   **Clarification:** The Controller determines ""what to do"" based on user action, effectively linking the Model and the View.\n\n### MVC Flow\n\nThe standard interaction flow is cyclical: The user interacts with the **View**; the **Controller** captures this input, updates the **Model**; and the **Model** (or the Controller) notifies the **View** to refresh and display the updated data.', False, 'None')"
What is a Deadlock?,"('A **Deadlock** is a state in concurrent computing where two or more competing processes or threads are indefinitely waiting for each other to release a resource that they require. Because each process is holding a resource and simultaneously waiting for another, none can proceed, resulting in system stagnation.\n\n### Four Necessary Conditions for Deadlock\n\nDeadlock can only occur if all four of the following conditions hold simultaneously:\n\n1.  **Mutual Exclusion:** At least one resource must be held in a non-sharable mode (i.e., only one process can use the resource at any given time).\n2.  **Hold and Wait (or Resource Holding):** A process must be holding at least one resource and simultaneously waiting to acquire additional resources currently held by other processes.\n3.  **No Preemption:** A resource cannot be forcibly taken away from a process that is holding it; the resource must only be released voluntarily by the process after it has completed its task.\n4.  **Circular Wait:** A set of waiting processes ($P_0, P_1, \\dots, P_n$) must exist such that $P_0$ is waiting for a resource held by $P_1$, $P_1$ is waiting for a resource held by $P_2$, and so on, with $P_n$ waiting for a resource held by $P_0$.\n\n### Common Method Used for Preventing Deadlock\n\nA common and highly effective method for preventing deadlocks involves eliminating the **Circular Wait** condition.\n\n*   **Resource Ordering:** Assign a global, unique ordering (numerical rank) to all lockable resources in the system. Processes are then required to request resources only in increasing order of enumeration. If a process needs resources $R_5$ and $R_2$, it must request $R_2$ first, then $R_5$. This restriction ensures that a circular wait dependency can never form, as all processes will be progressing along the same strictly ordered path.', False, 'None')"
What is a Closure in JavaScript?,"('A **Closure** is a feature in JavaScript where an inner function retains access to the scope (variables, parameters, and other functions) of its outer (enclosing) function, even after the outer function has finished execution and returned.\n\n### Mechanism for Retaining Access\n\nThe specific mechanism that enables a Closure is the **Lexical Environment** (or Lexical Scope).\n\n1.  When a function is defined in JavaScript, it forms a closure over the variables available in its immediate surrounding environment (its parent\'s scope).\n2.  If the outer function returns the inner function, the inner function carries a persistent reference to its parent\'s scope (the ""closure scope"").\n3.  This means that even though the outer function\'s execution context is destroyed from the stack, the variables it contained are not garbage collected because the returned inner function still references them.\n\nThis allows the inner function to ""remember"" and modify those variables later, even when executed elsewhere in the program.\n\n### Common Use Case: Data Privacy and Private Methods\n\nClosures are essential for creating **private variables** or **private methods** in JavaScript, a capability not natively provided by the language before ES6 classes.\n\n**Example:**\n\n```javascript\nfunction createCounter() {\n    let count = 0; // Private variable hidden in the outer scope\n    \n    return {\n        increment: function() {\n            count += 1;\n            return count;\n        },\n        getCount: function() {\n            return count;\n        }\n    };\n}\n\nconst counterA = createCounter();\ncounterA.increment(); // 1\n// The variable \'count\' is inaccessible directly (counterA.count is undefined),\n// ensuring the internal state is managed only by the exposed methods (the closures).\n```', False, 'None')"
What is the difference between an Interface and an Abstract Class?,"('In Object-Oriented Programming (OOP), both Interfaces and Abstract Classes are used to achieve abstraction and define a contract for subclasses, but they differ fundamentally in structure and application.\n\n### Primary Difference\n\n| Feature | Interface | Abstract Class |\n| :--- | :--- | :--- |\n| **Purpose** | Defines a contract (what an object *can* do). | Provides a base structure (what an object *is*). |\n| **Implementation** | Contains only method signatures (100% abstract, historically). | Can contain both abstract (unimplemented) and concrete (implemented) methods, and fields. |\n| **Fields** | Cannot contain instance fields or constructors (only static, final constants). | Can contain instance fields and a constructor. |\n| **Inheritance** | Supports **Multiple Inheritance** (a class can implement multiple interfaces). | Supports **Single Inheritance** (a class can only extend one abstract class). |\n\n### Specific Purpose and Constraints\n\n#### Interface (The Contract)\n\n*   **Purpose:** To specify public behavior that a class must implement, enabling **polymorphism** across unrelated classes. They focus on defining capabilities (e.g., `Serializable`, `Runnable`).\n*   **Constraints:** A class *implements* an interface. Because Interfaces only define behavior, a class can implement any number of interfaces without the complexity of managing conflicting inherited implementations (the Diamond Problem). Modern interfaces (Java 8+, C# 8+) may include default methods, providing limited implementation detail.\n\n#### Abstract Class (The Base Structure)\n\n*   **Purpose:** To provide a foundational blueprint for related subclasses, sharing common functionality while deferring certain specialized functions to the subclasses. They define a common **is-a** relationship (e.g., `Animal` is abstract, subclasses are `Dog`, `Cat`).\n*   **Constraints:** A class *extends* an abstract class. The extending class must implement all abstract methods defined in the parent class or also be declared abstract itself. Abstract classes enforce **Single Inheritance** to maintain a clear hierarchy and prevent ambiguity regarding method implementation inheritance.', False, 'None')"
What is a Load Balancer?,"('A **Load Balancer** is a specialized piece of hardware or software in network architecture that acts as a reverse proxy, distributing incoming network traffic across multiple servers (a server farm or server pool).\n\n### Primary Function and Benefits\n\nThe primary function of a Load Balancer is to efficiently and intelligently distribute the workload among multiple backend resources.\n\n**How it Improves Performance and Reliability:**\n\n*   **Performance:** By distributing the load, it prevents any single server from becoming a bottleneck, drastically reducing latency and maximizing throughput (request processing rate).\n*   **Scalability:** It allows administrators to easily add or remove servers (scaling horizontally) without interrupting application availability.\n*   **Reliability (High Availability):** Load balancers constantly monitor the health of the backend servers. If a server fails (a health check fails), the Load Balancer automatically stops sending traffic to it, ensuring that users are only directed to healthy, available resources. This process is critical for maintaining high availability.\n\n### Common Load Balancing Algorithms\n\nLoad Balancers use algorithms to determine which server receives the next request:\n\n1.  **Round Robin:** Requests are distributed sequentially to the servers in the pool. Server 1 gets the first request, Server 2 gets the second, and so on. This method is simple but does not account for differences in server capacity or current load.\n2.  **Least Connection:** The Load Balancer directs the incoming request to the server that currently has the fewest active connections. This is generally the most effective way to ensure an even distribution of the current workload.\n\n**Clarification:** Load Balancers often operate at either Layer 4 (Transport Layer, managing TCP/IP ports) or Layer 7 (Application Layer, managing HTTP headers and session data).', False, 'None')"
What is Microservices Architecture?,"(""**Microservices Architecture** is an architectural style that structures an application as a collection of small, independent services. Each service is self-contained, built around specific business capabilities, and can be developed, deployed, and scaled independently.\n\n### Contrast with Monolithic Architecture\n\n| Feature | Microservices Architecture | Monolithic Architecture |\n| :--- | :--- | :--- |\n| **Structure** | Decentralized; composed of many small, separate services. | Centralized; a single, tightly coupled codebase. |\n| **Technology** | Polyglot persistence (services can use different databases) and polyglot programming (different languages). | Usually uses a single technology stack and database. |\n| **Deployment** | Independent deployment; services can be updated without affecting the whole application. | Single, large deployment unit; one failure can halt the entire application. |\n\n### Key Characteristics Enabling Independence\n\nThe success of Microservices relies on characteristics that ensure components remain decoupled:\n\n1.  **Service Isolation:** Each service owns its data model and database (decentralized data management). This prevents one service's performance or schema changes from impacting others.\n2.  **Communication Protocols:** Services communicate via lightweight, standardized protocols, typically using APIs (like REST, gRPC, or messaging queues). The API acts as a clear boundary.\n3.  **Independent Deployment:** Services are packaged in lightweight containers (like Docker) and managed by orchestration tools (like Kubernetes), allowing them to be deployed and updated individually.\n4.  **Team Autonomy:** Teams are usually structured around specific business services, enabling them to choose the best technology stack for their particular component and facilitating faster development cycles.\n\n**Scaling:** Because services are independent, developers can scale only the specific services that are experiencing high load (e.g., scaling the payment processing service) rather than scaling the entire application infrastructure, which improves cost efficiency."", False, 'None')"
What is the CAP Theorem?,"(""The **CAP Theorem** (also known as Brewer's Theorem) is a fundamental principle in distributed systems stating that it is impossible for a distributed data store to simultaneously provide more than two out of the three following guarantees when a network partition occurs.\n\n### The Three Properties\n\nThe theorem concerns three core properties:\n\n1.  **Consistency (C):** Every read request receives the most recent write or an error. In a consistent system, all nodes in the distributed network agree on the state of the data simultaneously.\n2.  **Availability (A):** Every request receives a non-error response, without the guarantee that the response contains the most recent write. The system remains operational and accessible, even if some data is stale or incomplete.\n3.  **Partition Tolerance (P):** The system continues to operate despite arbitrary failures or loss of communication between nodes (network partitions).\n\n### Inherent Tradeoff\n\nIn any real-world distributed system, network failures (partitions) are inevitable. Therefore, **Partition Tolerance (P) is almost always considered mandatory.**\n\nThis forces distributed databases to choose between the remaining two properties:\n\n*   **CP Systems (Consistent and Partition Tolerant):** These systems prioritize accuracy and agreement. If a network partition occurs, the system will halt access to the parts of the system affected by the partition (sacrificing Availability) to ensure that the data read is always consistent. (Example: Traditional RDBMS, MongoDB, HBase).\n*   **AP Systems (Available and Partition Tolerant):** These systems prioritize uptime and responsiveness. If a network partition occurs, the system remains operational and accessible (sacrificing Consistency). It may return potentially stale data until the partition is resolved and the data can be synchronized (eventual consistency). (Example: Cassandra, CouchDB, DynamoDB)."", False, 'None')"
What is Polymorphism in OOP?,"('**Polymorphism** (Greek for ""many forms"") is a fundamental concept in Object-Oriented Programming (OOP) that allows objects of different classes to be treated as objects of a common type (their parent class or interface). This enables a single interface to control access to a general class of actions.\n\n### Two Main Types of Polymorphism\n\nPolymorphism is primarily achieved through two mechanisms:\n\n1.  **Static Polymorphism (Compile-Time Polymorphism):**\n    *   **Mechanism:** Achieved through **Method Overloading**, where multiple methods within the same class share the same name but have different parameter lists (different number or types of arguments).\n    *   **Resolution:** The specific method to be executed is determined by the compiler at compile time based on the arguments provided.\n\n2.  **Dynamic Polymorphism (Runtime Polymorphism):**\n    *   **Mechanism:** Achieved through **Method Overriding**, where a subclass provides a specific implementation for a method that is already defined in its superclass or interface.\n    *   **Resolution:** The specific method implementation executed is determined at runtime based on the actual type of the object, not the reference type.\n\n### Primary Benefit to Software Design\n\nThe primary benefit of Polymorphism is the **simplification and reduction of coupling** in code.\n\n*   **Decoupling:** By defining a common interface, Polymorphism allows developers to write code that interacts with the general parent type, rather than specific subtypes. This means new subclasses can be introduced without requiring modifications to the client code that uses the common interface.\n*   **Maintainability and Extensibility:** It drastically improves the flexibility and extensibility of the system, making the codebase easier to maintain, debug, and expand. For example, a function that accepts an `Animal` object can execute the `makeSound()` method correctly, regardless of whether the specific object passed at runtime is a `Dog`, `Cat`, or `Cow`.', False, 'None')"
What is Database Normalization?,"('**Database Normalization** is a systematic process in relational database design used to organize columns and tables efficiently.\n\n### Core Objective and Problems Solved\n\nThe core objective of normalization is to minimize data redundancy and dependencies within a relational database.\n\n**Problems it is intended to solve (Anomalies):**\n\n1.  **Insertion Anomalies:** Inability to add data to the database due to the absence of other data (e.g., being unable to add a new department until an employee is assigned to it).\n2.  **Deletion Anomalies:** Losing essential data unintentionally when deleting a row (e.g., deleting the last employee in a department removes all information about that department).\n3.  **Update Anomalies:** Having to update the same information in multiple places, leading to inconsistency if all copies are not updated successfully.\n\n### The First Three Standard Normal Forms\n\nNormalization proceeds in levels, called Normal Forms (NF). Achieving a higher form implies satisfying the requirements of all lower forms.\n\n1.  **First Normal Form (1NF):**\n    *   **Rule:** Eliminate repeating groups and ensure that every column value is atomic (indivisible) and non-multi-valued.\n2.  **Second Normal Form (2NF):**\n    *   **Rule:** Satisfies 1NF, and all non-key attributes must be fully dependent on the entire primary key. (This applies only if the primary key is a composite key).\n3.  **Third Normal Form (3NF):**\n    *   **Rule:** Satisfies 2NF, and no non-key attribute is dependent on another non-key attribute (i.e., eliminating transitive dependencies).\n\n**Clarification:** Most transactional databases aim for the Third Normal Form (3NF) or the slightly stricter Boyce-Codd Normal Form (BCNF), as these forms strike the best balance between reducing redundancy and maintaining acceptable query performance. Higher forms (4NF, 5NF) exist but are rarely implemented in practice.', False, 'None')"
How does Binary Search work?,"('The **Binary Search** algorithm is an efficient method for finding the position of a target value within a list of elements. It works by repeatedly dividing the search interval in half.\n\n### How Binary Search Works\n\n1.  **Start:** Define the search range by establishing the lowest index (low) and the highest index (high) of the data structure.\n2.  **Midpoint Calculation:** Calculate the index of the middle element (`mid = (low + high) / 2`).\n3.  **Comparison:** Compare the value at the midpoint index with the target value.\n    *   If the values match, the search is successful, and the index is returned.\n    *   If the target value is less than the midpoint value, the algorithm eliminates the upper half of the array and sets the `high` index to `mid - 1`.\n    *   If the target value is greater than the midpoint value, the algorithm eliminates the lower half of the array and sets the `low` index to `mid + 1`.\n4.  **Iteration:** Steps 2 and 3 are repeated until the value is found or the search interval is empty (`low` > `high`).\n\n### Critical Precondition\n\nThe critical precondition for Binary Search to function correctly is that the **input data (array or list) must be sorted**. If the data is not sorted, the comparison logic breaks down, and the algorithm cannot guarantee a correct result.\n\n### Time Complexity Analysis\n\nBecause Binary Search halves the search space in every step, it is drastically faster than linear search, especially for large datasets.\n\n*   **Best Case:** $O(1)$\n    *   The target element is found immediately on the first comparison (the element is exactly at the middle index).\n*   **Average Case:** $O(\\log n)$\n    *   The time required grows logarithmically with the size of the input ($n$).\n*   **Worst Case:** $O(\\log n)$\n    *   The target element is found just before the final step, or it is not present in the list.', False, 'None')"
What is a JSON Web Token (JWT)?,"('A **JSON Web Token (JWT)** is a compact, URL-safe means of representing claims (pieces of information) to be transferred between two parties. JWTs are often used for secure authentication and authorization in modern web applications.\n\n### Standard Three-Part Structure\n\nA JWT is typically represented as a string consisting of three parts, separated by dots (`.`):\n\n1.  **Header:**\n    *   Contains metadata about the token itself, primarily the type of token (which is generally ""JWT"") and the hashing algorithm used for signing (e.g., HMAC SHA256 or RSA).\n2.  **Payload (Claims):**\n    *   Contains the claims (statements) about an entity (usually the user) and additional data. Claims can include standard reserved claims (like expiration time `exp`), public claims (defined by users), or private claims (custom information).\n3.  **Signature:**\n    *   Created by taking the Base64Url-encoded Header, the Base64Url-encoded Payload, and signing them using the secret key known only to the server, according to the algorithm specified in the Header.\n\n**Clarification:** The Header and Payload are only Base64 encoded, meaning they are not encrypted and can be easily read. The Signature is what guarantees the integrity (non-tampering) of the data.\n\n### Primary Role in Secure Authentication\n\nJWTs are fundamental to **stateless authentication**, particularly in API-driven and microservices architectures:\n\n*   **Authentication:** When a user successfully logs in, the server generates a JWT containing the user\'s ID and permissions, signs it, and sends it back to the client.\n*   **Authorization:** For subsequent requests, the client sends the JWT (usually in the Authorization header). The server validates the signature using the secret key. If the signature is valid, the server trusts the claims within the payload, grants access to protected resources, and avoids the need to repeatedly query a session database for every request.', False, 'None')"
What is CORS?,"('**Cross-Origin Resource Sharing (CORS)** is a browser security mechanism that allows web pages (running on one origin) to request resources from another origin (domain, protocol, or port) under specific, controlled circumstances.\n\n### Security Problem Solved\n\nCORS is designed to overcome the limitations imposed by the **Same-Origin Policy (SOP)**.\n\n*   **Same-Origin Policy (SOP):** This is a critical browser security feature that, by default, restricts a document or script loaded from one origin from interacting with a resource from another origin. This prevents malicious scripts loaded from one site (e.g., `attacker.com`) from making unauthorized requests or reading sensitive data from another site (e.g., `bank.com`) where the user is logged in.\n*   **CORS Function:** CORS provides a secure, controlled way to relax the SOP restriction by having the server explicitly grant permission to the requesting origin via specific HTTP headers (like `Access-Control-Allow-Origin`).\n\n### Simple Request vs. Preflight Request\n\nThe browser determines the appropriate handling of a cross-origin request based on its complexity:\n\n1.  **Simple Request:**\n    *   **Definition:** Requests that meet specific criteria (e.g., using only GET, HEAD, or POST methods; using only certain standard headers; and having a specific Content-Type).\n    *   **Process:** The browser sends the request directly, adding the `Origin` header. The server must then respond with the appropriate CORS headers.\n\n2.  **Preflight Request:**\n    *   **Definition:** Requests that are potentially risky or use complex methods (e.g., PUT, DELETE, or custom headers).\n    *   **Process:** Before sending the actual request, the browser first sends an automatic preliminary request using the **OPTIONS** method. This preflight request asks the server for permission about the method and headers the main request intends to use. Only if the server explicitly authorizes the action in its OPTIONS response headers will the browser proceed with the actual data request.', False, 'None')"
What is Dependency Injection?,"(""**Dependency Injection (DI)** is a software design pattern where components receive their necessary dependencies (other objects they rely on) from an external source rather than creating them internally.\n\n### Relationship to Inversion of Control (IoC)\n\nDependency Injection is a specific technique used to implement the broader principle known as **Inversion of Control (IoC)**.\n\n*   **IoC Principle:** States that the control over object creation and lifecycle management should be inverted, meaning the responsibility is shifted from the component itself to an external framework or mechanism (often called a container or injector).\n*   **DI Implementation:** Dependency Injection is the mechanism by which the external framework (the IoC Container) injects or supplies the required dependencies into the object, typically via the object's constructor, properties, or methods.\n\nBy using DI, the class is not responsible for knowing *how* to build its dependencies; it just assumes they will be provided.\n\n### Primary Benefits for Code Maintainability and Testing\n\nDI significantly improves code quality and architecture:\n\n1.  **Reduced Coupling and Increased Maintainability:** DI ensures components are loosely coupled. If the internal implementation of a dependency changes, the dependent component usually does not need modification, provided the interface remains the same. This makes the system much easier to maintain and update.\n2.  **Facilitated Unit Testing:** This is one of the greatest benefits. When using DI, it is trivial to replace real dependencies with **Mocks** or **Stubs** during unit testing. Since the dependency is supplied externally, the test runner can easily inject a fake object that tracks behavior or returns predictable results, isolating the component being tested and making tests reliable and fast.\n\n**Clarification:** The three main ways to perform DI are **Constructor Injection**, **Setter/Property Injection**, and **Method Injection**. Constructor injection is generally preferred as it guarantees the object is created with all necessary dependencies."", False, 'None')"
What is GraphQL?,"(""**GraphQL** is a query language for APIs and a server-side runtime for executing those queries by using a type system defined for your data. It was developed by Facebook to optimize client-server communication.\n\n### Contrast with Traditional REST APIs\n\n| Feature | GraphQL | Traditional REST |\n| :--- | :--- | :--- |\n| **Data Fetching** | Client declares exactly the data fields required. | Server dictates the data structure; endpoints return fixed datasets. |\n| **Endpoint Structure** | Typically a single endpoint (e.g., `/graphql`). | Multiple, resource-specific endpoints (e.g., `/users`, `/users/123/posts`). |\n| **Relationship Handling** | Related data (e.g., a user's posts) can be fetched in a single request. | Requires multiple round trips (waterfall requests) to gather related data. |\n\n### Key Advantage: Preventing Over- and Under-Fetching\n\nGraphQL's main advantage regarding bandwidth usage and payload size is the elimination of **over-fetching** and **under-fetching**:\n\n1.  **Eliminating Over-fetching:** In REST, an endpoint might return 50 fields when the client only needs 5. GraphQL allows the client to specify only the fields it needs, dramatically reducing the size of the data payload and conserving bandwidth, which is crucial for mobile clients or slow networks.\n2.  **Eliminating Under-fetching:** In REST, gathering complex or related data often requires the client to make multiple successive requests (under-fetching data on the first call). GraphQL resolves this by gathering all required data (including related objects) into a single, efficient request, reducing the number of network round trips.\n\n**Clarification:** GraphQL relies on a strongly typed schema that defines all possible data fields and relationships, which allows for better client-side tooling and validation."", False, 'None')"
What is the difference between Stack and Heap memory?,"('The **Stack** and the **Heap** are two fundamental regions of memory used by a running program, differentiated primarily by how memory is allocated, managed, and accessed.\n\n### Fundamental Difference\n\n| Feature | Stack Memory | Heap Memory |\n| :--- | :--- | :--- |\n| **Allocation** | Static, LIFO (Last-In, First-Out) manner. | Dynamic; memory allocated and deallocated randomly. |\n| **Speed** | Very fast access (managed by the CPU). | Slower access (requires pointer dereferencing). |\n| **Management** | Automatic by the compiler/OS (memory freed when the function returns). | Manual (by the programmer, e.g., C/C++) or automatic (by Garbage Collector, e.g., Java/C#). |\n| **Size Constraint** | Small, fixed size defined at compile time (leading to Stack Overflow errors). | Large, flexible size (limited by physical RAM). |\n\n### Specific Data Stored\n\n*   **Stack Data:** Primarily stores **Value Types** and metadata related to function calls:\n    *   Primitive variables (integers, booleans, characters).\n    *   References (pointers) to objects stored on the Heap.\n    *   Function call frames (local variables and return addresses).\n*   **Heap Data:** Primarily stores **Reference Types** and large, complex, or long-lived data:\n    *   Objects, arrays, and complex data structures.\n    *   Data whose size is not known at compile time.\n\n### Consequences of Distinct Memory Management\n\n1.  **Locality and Speed (Stack):** Due to its strict LIFO order, Stack memory accesses are highly localized (close together in physical memory). This allows the CPU to use caches effectively, resulting in extremely fast allocation and deallocation compared to the Heap.\n2.  **Memory Leaks (Heap):** Since Heap memory is dynamically managed, improper handling (especially in languages without automatic garbage collection) can lead to **memory leaks** (allocated memory that is no longer accessible but never freed). In languages with Garbage Collection (GC), performance can be impacted by the time spent cleaning up unused Heap objects.\n3.  **Thread Safety:** Each thread usually gets its own dedicated Stack, meaning Stack variables are inherently thread-safe. The Heap, conversely, is typically shared across all threads, requiring synchronization mechanisms (like locks) when accessing shared objects.', False, 'None')"
What are ACID properties in databases?,"('The **ACID properties** are a set of principles used to guarantee that database transactions are processed reliably. These properties are critical for transactional systems (like banking or inventory management) where data integrity is paramount.\n\n### The Four Acronym Letters\n\nThe ACID acronym stands for:\n\n1.  **A - Atomicity:** A transaction must be treated as a single, indivisible unit of work. It must either fully complete (commit) or completely fail (rollback). There is no intermediate state.\n2.  **C - Consistency:** A transaction must bring the database from one valid state to another. Any data written to the database must adhere to all defined rules, constraints, and triggers (e.g., uniqueness, foreign keys).\n3.  **I - Isolation:** Concurrent transactions must execute in such a way that the execution of one does not affect the execution of others. To the user, it must appear as if only one transaction is executing at a time.\n4.  **D - Durability:** Once a transaction has been successfully committed, its changes must be permanent, surviving subsequent system failures, power loss, or crashes.\n\n### Criticality for Maintaining Data Integrity\n\nThe ACID properties are critical because they provide a framework that guarantees the trustworthiness and accuracy of data, especially under adverse conditions:\n\n*   **Financial Accuracy:** In a banking transaction (transferring money from Account A to Account B), Atomicity ensures that either both the debit and credit succeed, or neither does, preventing money from being lost or duplicated.\n*   **Reliable State:** Consistency guarantees that business rules are never violated, ensuring the data always makes logical sense (e.g., account balances never drop below zero).\n*   **Concurrency Management:** Isolation prevents transactions from interfering with each other, eliminating concurrency problems like dirty reads or phantom reads, thus maintaining data reliability even when thousands of users are accessing the data simultaneously.', False, 'None')"
What are WebSockets?,"('**WebSockets** are a communication protocol that provides a full-duplex, persistent communication channel over a single, long-lived TCP connection. They are designed for real-time, low-latency applications in web browsers and servers.\n\n### Technical Limitation Overcome\n\nWebSockets were designed primarily to overcome the limitations of the traditional **HTTP Request/Response cycle** and the resulting inefficiency of simulating real-time communication.\n\n*   **HTTP Limitation:** Standard HTTP is a stateless, one-way protocol where communication must be initiated by the client. To get real-time updates from the server, developers had to use inefficient techniques like **polling** (the client repeatedly asks the server for new data) or **long polling** (the server holds the request open until data is available). These techniques involve high latency, significant header overhead, and consume unnecessary bandwidth.\n*   **WebSocket Solution:** WebSockets create a persistent, bidirectional channel, allowing the server to push data to the client whenever new information is available, without waiting for the client to request it.\n\n### Method Used to Establish Connection\n\nA WebSocket connection is established using a special mechanism called the **HTTP Handshake**.\n\n1.  **Client Request:** The client sends a standard HTTP request to the server, but it includes special headers, notably `Upgrade: websocket` and `Connection: Upgrade`.\n2.  **Server Response:** If the server supports WebSockets, it acknowledges the upgrade request by responding with an HTTP status code of **101 Switching Protocols** and includes the necessary WebSocket headers.\n3.  **Connection Established:** Upon receiving the 101 response, the client and server transition from HTTP to the WebSocket protocol, establishing the permanent, low-overhead, bidirectional connection that remains open until explicitly closed by either side.\n\n**Clarification:** Once the handshake is complete, all subsequent data transfer occurs over the established TCP channel using the WebSocket protocol, which uses much smaller frame-based messages instead of large HTTP request/response headers.', False, 'None')"
What is Memoization?,"('**Memoization** is an optimization technique used primarily to speed up computer programs by caching the results of expensive function calls and returning the cached result when the same inputs occur again.\n\n### Critical Conditions for Effectiveness\n\nMemoization is only effective and worthwhile if the target function meets two critical conditions:\n\n1.  **High Cost (Expensive):** The function must involve a significant computational cost (e.g., complex calculations, recursive processing, or database queries). If the function is trivial, the overhead of managing the cache outweighs the performance gain.\n2.  **Referential Transparency (Purity):** The function must be **pure**, meaning that for the same input arguments, it must always return the same output, and it must not have any side effects (e.g., modifying global state or performing I/O operations). This ensures that the cached result remains valid indefinitely for those inputs.\n\n### Primary Benefit to Computational Efficiency\n\nThe primary benefit of Memoization is the reduction of redundant computation, leading to massive improvements in time complexity, especially for recursive functions with overlapping subproblems (e.g., calculating Fibonacci numbers).\n\n*   **Time Savings:** Instead of re-executing the entire logic of an expensive function, the system only performs a fast lookup operation against the cache (usually a hash map or dictionary).\n*   **Tradeoff:** Memoization trades space (using extra memory to store the cache) for time (saving processing cycles). In contexts like dynamic programming, it transforms exponential time complexity problems into polynomial or linear time problems.\n\n**Clarification:** Memoization is often confused with Caching. Caching is a broad term for storing data temporarily. Memoization is a form of caching specifically applied to the return values of functions based on their input parameters.', False, 'None')"
What is a Singleton Pattern?,"(""The **Singleton Pattern** is a creational design pattern in object-oriented programming (OOP) that restricts the instantiation of a class to a single object.\n\n### Main Objective in Application Design\n\nThe main objective of the Singleton Pattern is to provide a **single, global point of access** to a specific resource or service. This is necessary when exactly one instance of a class is required to coordinate actions across the entire system.\n\n**Common Use Cases:**\n\n*   **Logging:** A single logging object ensures that all log messages are routed correctly and sequentially to the same file or destination.\n*   **Configuration Manager:** Providing centralized access to application-wide settings.\n*   **Connection Pools:** Managing a fixed number of database connections efficiently across the application.\n\n### Mechanism Used to Ensure Only One Instance\n\nThe Singleton Pattern enforces its constraint through a multi-step mechanism involving class construction:\n\n1.  **Private Constructor:** The class's constructor is made private or protected. This prevents external code from using the `new` keyword to create new instances directly.\n2.  **Static Instance Variable:** A static field is declared within the class to hold the single instance of the class. This instance is usually initialized lazily (created only when first requested) or eagerly (created immediately upon class loading).\n3.  **Public Static Factory Method:** A public static method (often named `getInstance()`) is provided. This is the only way to access the instance. When called, the method checks if the static instance variable is null; if it is, the object is created and stored. If it is not null, the existing instance is simply returned.\n\n**Clarification:** In multithreaded environments, the Singleton Pattern must employ locking or synchronization mechanisms (like double-checked locking) within the `getInstance()` method to prevent two threads from simultaneously creating two different instances."", False, 'None')"
